{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "82fe5299-78b3-4442-b8ac-d9632c01da40",
      "metadata": {
        "id": "82fe5299-78b3-4442-b8ac-d9632c01da40",
        "outputId": "e2bb2b81-556d-4f03-c907-d5e6532a6655",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "text = \"Hello, world. This, is a test.\"\n",
        "result = re.split(r'(\\s)', text)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "be986c47-ade8-4d73-ae6f-c2fbef88c6ed",
      "metadata": {
        "id": "be986c47-ade8-4d73-ae6f-c2fbef88c6ed",
        "outputId": "fa77ec7a-5e35-45aa-9ce8-4a339b272eab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ],
      "source": [
        "result = re.split(r'([,.]|\\s)', text)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "826cff60-325b-4188-a02d-4d6eb0e7ceac",
      "metadata": {
        "id": "826cff60-325b-4188-a02d-4d6eb0e7ceac",
        "outputId": "0d558720-6769-4ac2-8ece-4ae21da29179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ],
      "source": [
        "result = [item for item in result if item.strip()]\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f3c050c9-d564-41e1-8798-9e56c5ac05de",
      "metadata": {
        "id": "f3c050c9-d564-41e1-8798-9e56c5ac05de",
        "outputId": "6fc5c91c-e071-4af0-af04-21f0d98e4b42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'the-verdict.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1843485556.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"the-verdict.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mraw_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total number of character:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m99\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'the-verdict.txt'"
          ]
        }
      ],
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b9b76013-fbcb-412e-89d1-3764ec24020a",
      "metadata": {
        "id": "b9b76013-fbcb-412e-89d1-3764ec24020a"
      },
      "outputs": [],
      "source": [
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(len(preprocessed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19bb15be-b0f5-4da1-b1ef-e253e0baeff4",
      "metadata": {
        "id": "19bb15be-b0f5-4da1-b1ef-e253e0baeff4"
      },
      "outputs": [],
      "source": [
        "print(preprocessed[:30])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2823f7a-8c5f-4a51-9b9e-34043dca7aa7",
      "metadata": {
        "id": "a2823f7a-8c5f-4a51-9b9e-34043dca7aa7"
      },
      "outputs": [],
      "source": [
        "all_words = sorted(set(preprocessed))\n",
        "vocab_size = len(all_words)\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f379f99f-9764-40a5-9d22-a5908a20ee58",
      "metadata": {
        "id": "f379f99f-9764-40a5-9d22-a5908a20ee58"
      },
      "outputs": [],
      "source": [
        "vocab = {token:integer for integer,token in enumerate(all_words)}\n",
        "for i, item in enumerate(vocab.items()):\n",
        "    print(item)\n",
        "    if i >= 50:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c68bedd7-71ee-48d0-abe4-ea3fecdee15a",
      "metadata": {
        "id": "c68bedd7-71ee-48d0-abe4-ea3fecdee15a"
      },
      "outputs": [],
      "source": [
        "class SimpleTokenizerV1:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [\n",
        "        item.strip() for item in preprocessed if item.strip()\n",
        "        ]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92edc714-0ddd-4098-9595-97aadb060a9c",
      "metadata": {
        "id": "92edc714-0ddd-4098-9595-97aadb060a9c"
      },
      "outputs": [],
      "source": [
        "tokenizer = SimpleTokenizerV1(vocab)\n",
        "text = \"\"\"\"It's the last he painted, you know,\"\n",
        "    Mrs. Gisburn said with pardonable pride.\"\"\"\n",
        "ids = tokenizer.encode(text)\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "90933fa2-8efc-415a-b26c-9b9b690df722",
      "metadata": {
        "id": "90933fa2-8efc-415a-b26c-9b9b690df722",
        "outputId": "61700f6c-92b9-40a1-c700-57a4faedb283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tokenizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-685867356.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
          ]
        }
      ],
      "source": [
        "print(tokenizer.decode(ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d082d632-b00a-4291-a1e3-6fd65e5ccb1d",
      "metadata": {
        "id": "d082d632-b00a-4291-a1e3-6fd65e5ccb1d"
      },
      "outputs": [],
      "source": [
        "all_tokens = sorted(list(set(preprocessed)))\n",
        "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
        "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
        "print(len(vocab.items()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3438f6d-1ce5-449a-86be-0b7104d3d96c",
      "metadata": {
        "id": "f3438f6d-1ce5-449a-86be-0b7104d3d96c"
      },
      "outputs": [],
      "source": [
        "for i, item in enumerate(list(vocab.items())[-5:]):\n",
        "    print(item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d203f16",
      "metadata": {
        "id": "4d203f16"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "974ca4d6-3dd1-4e33-a668-3c947d22f4f7",
      "metadata": {
        "id": "974ca4d6-3dd1-4e33-a668-3c947d22f4f7"
      },
      "outputs": [],
      "source": [
        "class SimpleTokenizerV2:\n",
        "    def __init__(self, vocab):\n",
        "        self.str_to_int = vocab\n",
        "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
        "\n",
        "    def encode(self, text):\n",
        "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
        "        preprocessed = [\n",
        "            item.strip() for item in preprocessed if item.strip()\n",
        "        ]\n",
        "        preprocessed = [\n",
        "            item if item in self.str_to_int\n",
        "            else \"<|unk|>\" for item in preprocessed\n",
        "        ]\n",
        "        ids = [self.str_to_int[s] for s in preprocessed]\n",
        "        return ids\n",
        "    def decode(self, ids):\n",
        "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
        "\n",
        "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "376200ff-a0a9-41fd-bfc3-5fe81336ad64",
      "metadata": {
        "id": "376200ff-a0a9-41fd-bfc3-5fe81336ad64",
        "outputId": "5eeac4ea-aa46-4e36-8f9a-59982f128831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
          ]
        }
      ],
      "source": [
        "text1 = \"Hello, do you like tea?\"\n",
        "text2 = \"In the sunlit terraces of the palace.\"\n",
        "text = \" <|endoftext|> \".join((text1, text2))\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "606c65ea-5e8c-4d17-8062-bc313ae1dc87",
      "metadata": {
        "id": "606c65ea-5e8c-4d17-8062-bc313ae1dc87",
        "outputId": "56c2f122-d18c-4c6c-90cf-6071e51ea705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'vocab' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3267124711.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleTokenizerV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vocab' is not defined"
          ]
        }
      ],
      "source": [
        "tokenizer = SimpleTokenizerV2(vocab)\n",
        "print(tokenizer.encode(text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4254f49b-0b76-46c7-9568-78f84a6cb34a",
      "metadata": {
        "id": "4254f49b-0b76-46c7-9568-78f84a6cb34a"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(tokenizer.encode(text)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6255d66e",
      "metadata": {
        "id": "6255d66e",
        "outputId": "1d6d7978-0af0-49ea-e841-8e57d29d5054",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tiktoken version: 0.12.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a5d2586b",
      "metadata": {
        "id": "a5d2586b"
      },
      "outputs": [],
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uKbtl45Ji0OR"
      },
      "id": "uKbtl45Ji0OR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41340d9a",
      "metadata": {
        "id": "41340d9a"
      },
      "outputs": [],
      "source": [
        "text = (\n",
        "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
        "    \"of someunknownPlace.\"\n",
        ")\n",
        "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(integers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4150d4cb",
      "metadata": {
        "id": "4150d4cb"
      },
      "outputs": [],
      "source": [
        "strings = tokenizer.decode(integers)\n",
        "print(strings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ca41e6",
      "metadata": {
        "id": "16ca41e6"
      },
      "outputs": [],
      "source": [
        "text = 'Akwirw ier'\n",
        "ex21 = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
        "print(ex21)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aedb174",
      "metadata": {
        "id": "9aedb174"
      },
      "outputs": [],
      "source": [
        "print(tokenizer.decode(ex21))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}